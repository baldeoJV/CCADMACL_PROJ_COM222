{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Physical Activity Clustering â€“ Identify patterns in physical activity levels and their correlation with health outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Physical Activity Data\n",
    "# PAXMIN, PAXMIAF, PAXTMIN, PAXTMAF (Physical Activity Monitor - PAM)\n",
    "# These files contain accelerometer-based physical activity measurements, which provide objective measures of movement intensity and duration.\n",
    "# PAQ (Physical Activity Questionnaire)\n",
    "# Self-reported physical activity levels, including time spent in moderate and vigorous activities.\n",
    "\n",
    "# 2. Health Outcomes Data\n",
    "# BMX (Body Measures)\n",
    "# Contains BMI, waist circumference, and other obesity-related metrics.\n",
    "# DIQ (Diabetes)\n",
    "# Includes self-reported diabetes diagnosis and prediabetes indicators.\n",
    "# MCQ (Medical Conditions)\n",
    "# Contains self-reported cardiovascular disease (heart attack, stroke, heart failure, etc.) and other health conditions.\n",
    "\n",
    "# 3. Demographics and Other Relevant Data\n",
    "# DEMO (Demographics)\n",
    "# Includes age, gender, race, socioeconomic status, which could be useful for additional analysis of clustering patterns.\n",
    "# BPX (Blood Pressure & Hypertension Status)\n",
    "# Important for understanding cardiovascular risks.\n",
    "# LAB Data (Glucose, Cholesterol, etc.)\n",
    "# Useful for linking physical activity patterns with metabolic health indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def convert_to_weekly(frequency, unit):\n",
    "    \"\"\"Converts activity frequency to a weekly scale based on unit.\"\"\"\n",
    "    conversion_factors = {1: 1, 2: 7, 3: 30, 4: 365}  # Day, Week, Month, Year\n",
    "    return frequency * conversion_factors.get(unit, 1)\n",
    "\n",
    "# Load NHANES datasets\n",
    "dataframes = {\n",
    "    \"PAQ_L\": pd.read_sas(\"PAQ_L.xpt\", format=\"xport\"),\n",
    "    \"BMX_L\": pd.read_sas(\"BMX_L.xpt\", format=\"xport\"),\n",
    "    \"DIQ_L\": pd.read_sas(\"DIQ_L.xpt\", format=\"xport\"),\n",
    "    \"MCQ_L\": pd.read_sas(\"MCQ_L.xpt\", format=\"xport\"),\n",
    "    \"BPXO_L\": pd.read_sas(\"BPXO_L.xpt\", format=\"xport\"),\n",
    "    \"GLU_L\": pd.read_sas(\"GLU_L.xpt\", format=\"xport\"),\n",
    "    \"INS_L\": pd.read_sas(\"INS_L.xpt\", format=\"xport\"),\n",
    "    \"HSCRP_L\": pd.read_sas(\"HSCRP_L.xpt\", format=\"xport\"),\n",
    "    \"TCHOL_L\": pd.read_sas(\"TCHOL_L.xpt\", format=\"xport\"),\n",
    "    \"DEMO_L\": pd.read_sas(\"DEMO_L.xpt\", format=\"xport\")\n",
    "}\n",
    "\n",
    "# Convert byte-string columns to standard string format\n",
    "def decode_bytes(df):\n",
    "    for col in df.select_dtypes(include=['object']):\n",
    "        df[col] = df[col].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "    return df\n",
    "\n",
    "dataframes = {name: decode_bytes(df) for name, df in dataframes.items()}\n",
    "\n",
    "# Merge datasets on 'SEQN'\n",
    "df = dataframes[\"PAQ_L\"]\n",
    "for name, df_other in dataframes.items():\n",
    "    if name != \"PAQ_L\":\n",
    "        df = df.merge(df_other, on=\"SEQN\", how=\"inner\")\n",
    "\n",
    "# Convert activity frequencies to weekly scale if available\n",
    "if \"PAD790Q\" in df.columns and \"PAD790U\" in df.columns:\n",
    "    df[\"ModerateActivityWeekly\"] = df.apply(lambda row: convert_to_weekly(row[\"PAD790Q\"], row[\"PAD790U\"]), axis=1)\n",
    "if \"PAD810Q\" in df.columns and \"PAD810U\" in df.columns:\n",
    "    df[\"VigorousActivityWeekly\"] = df.apply(lambda row: convert_to_weekly(row[\"PAD810Q\"], row[\"PAD810U\"]), axis=1)\n",
    "\n",
    "# Calculate Total Physical Activity if necessary columns exist\n",
    "if \"ModerateActivityWeekly\" in df.columns and \"PAD800\" in df.columns and \"VigorousActivityWeekly\" in df.columns and \"PAD820\" in df.columns:\n",
    "    df[\"TotalPhysicalActivity\"] = (df[\"ModerateActivityWeekly\"] * df[\"PAD800\"]) + (df[\"VigorousActivityWeekly\"] * df[\"PAD820\"] * 2)\n",
    "\n",
    "# Categorize Physical Activity Levels (Based on WHO Guidelines)\n",
    "def categorize_activity(minutes):\n",
    "    if minutes < 150:\n",
    "        return \"Low\"\n",
    "    elif 150 <= minutes <= 300:\n",
    "        return \"Moderate\"\n",
    "    else:\n",
    "        return \"High\"\n",
    "\n",
    "df[\"ActivityCategory\"] = df[\"TotalPhysicalActivity\"].apply(categorize_activity) if \"TotalPhysicalActivity\" in df.columns else \"Unknown\"\n",
    "\n",
    "# Create binary health condition flags based on available columns\n",
    "if \"BMXBMI\" in df.columns:\n",
    "    df[\"Obese\"] = (df[\"BMXBMI\"] >= 30).astype(int)\n",
    "if \"DIQ010\" in df.columns:\n",
    "    df[\"Diabetes\"] = (df[\"DIQ010\"] == 1).astype(int)\n",
    "if \"MCQ160E\" in df.columns:\n",
    "    df[\"CVD\"] = df[\"MCQ160E\"].notnull().astype(int)\n",
    "if \"BPXSY1\" in df.columns and \"BPXDI1\" in df.columns:\n",
    "    df[\"Hypertension\"] = ((df[\"BPXSY1\"] >= 130) | (df[\"BPXDI1\"] >= 80)).astype(int)\n",
    "\n",
    "# Select only relevant columns that exist in the dataset\n",
    "final_columns = [\n",
    "    \"SEQN\", \"PAD790Q\", \"PAD790U\", \"PAD800\", \"PAD810Q\", \"PAD810U\", \"PAD820\", \"PAD680\",\n",
    "    \"TotalPhysicalActivity\", \"ActivityCategory\", \"BMXBMI\", \"BMXWAIST\", \"Obese\",\n",
    "    \"DIQ010\", \"Diabetes\", \"MCQ160E\", \"CVD\", \"BPXSY1\", \"BPXDI1\", \"Hypertension\",\n",
    "    \"LBXGLU\", \"LBXINS\", \"LBXHSCRP\", \"LBXTC\", \"RIDAGEYR\", \"RIAGENDR\", \"INDFMPIR\"\n",
    "]\n",
    "df = df[[col for col in final_columns if col in df.columns]]\n",
    "\n",
    "# Convert non-numeric columns to NaN before computing median\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Handle missing values: Fill NaNs with column medians\n",
    "df.fillna(df.median(), inplace=True)\n",
    "\n",
    "# Normalize numerical features for clustering\n",
    "numeric_features = [col for col in [\"TotalPhysicalActivity\", \"BMXBMI\", \"BMXWAIST\", \"BPXSY1\", \"BPXDI1\", \"LBXGLU\", \"LBXINS\", \"LBXHSCRP\", \"LBXTC\"] if col in df.columns]\n",
    "scaler = StandardScaler()\n",
    "df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "\n",
    "# Save final dataset\n",
    "df.to_csv(\"NHANES_2021_Clustering_Dataset.csv\", index=False)\n",
    "\n",
    "print(\"Final dataset saved as 'NHANES_2021_Clustering_Dataset.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trainingArc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
